---
title: "Demand Forecasting Analysis"
author: "Midland Purhasing Team"
date: today
format:
  html:
    theme: cosmo
    toc: true
    toc-location: left
    code-fold: true
    code-tools: true
    fig-width: 10
    fig-height: 6
execute:
  echo: true
  warning: false
  message: false
  error: false
---

# Executive Summary

This analysis examines supply chain lead time performance across 195 parts, revealing critical insights into delivery reliability and risk assessment. The analysis categorizes parts into risk levels based on lead time variability, on-time performance, and reliability scores.

**Key Findings:**
- 77.9% of parts are classified as high or critical risk
- Only 3.6% of parts demonstrate reliable performance
- Average on-time delivery rate is 40.1%
- Significant opportunity for supply chain optimization

# Data Overview

```{python}
# Test Python execution
print("Python is working!")

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Load the data
try:
    df = pd.read_excel('lead_time_analysis_wf.xlsx', sheet_name='Lead_Time_Stats')
    print(f"✅ Dataset loaded: {len(df)} parts with {df.shape[1]} metrics")
    df.head()
except FileNotFoundError:
    print("❌ Excel file not found. Please ensure 'lead_time_analysis_wf.xlsx' is in the working directory.")
    # Create sample data for demonstration
    df = pd.DataFrame({
        'Product': ['1100A', '1100B', '116', '116R', '119'],
        'risk_category': ['HIGH_RISK', 'LOW_RISK', 'HIGH_RISK', 'MEDIUM_RISK', 'CRITICAL_RISK'],
        'on_time_rate': [50.0, 100.0, 20.0, 66.7, 0.0],
        'lead_time_mean': [31.0, 20.0, 33.0, 23.67, 25.0]
    })
    print("Using sample data for demonstration")
    df
```

# Risk Analysis

## Risk Category Distribution

```{python}
# Calculate risk distribution
risk_counts = df['risk_category'].value_counts()
risk_percent = df['risk_category'].value_counts(normalize=True) * 100

summary_df = pd.DataFrame({'Count': risk_counts, 'Percentage': risk_percent.round(2)})
print("Supply Chain Risk Distribution:")
print(summary_df)
```

## Risk Visualization

```{python}
# Create risk distribution pie chart
risk_breakdown = df['risk_category'].value_counts()

plt.figure(figsize=(12, 5))

# Risk categories pie chart
plt.subplot(1, 2, 1)
colors = ['#FF6B6B', '#FFE66D', '#FF9F43', '#51CF66']
wedges, texts, autotexts = plt.pie(risk_breakdown.values, labels=risk_breakdown.index, 
                                   autopct='%1.1f%%', colors=colors, startangle=90)
plt.title('Supply Chain Risk Distribution', fontsize=14, fontweight='bold')

# On-time performance histogram
plt.subplot(1, 2, 2)
plt.hist(df['on_time_rate'], bins=20, alpha=0.7, color='#FF6B6B', edgecolor='black')
plt.xlabel('On-Time Rate (%)')
plt.ylabel('Number of Parts')
plt.title('On-Time Performance Distribution', fontsize=14, fontweight='bold')
plt.axvline(df['on_time_rate'].mean(), color='red', linestyle='--', 
            label=f'Mean: {df["on_time_rate"].mean():.1f}%')
plt.legend()
plt.tight_layout()
plt.show()
```

# Performance Metrics

## Key Statistics

```{python}
# Calculate key performance indicators
high_critical_count = risk_breakdown['HIGH_RISK'] + risk_breakdown['CRITICAL_RISK']
low_risk_count = risk_breakdown['LOW_RISK']
avg_on_time = df['on_time_rate'].mean()
avg_lead_time = df['lead_time_mean'].mean()

print("📊 SUPPLY CHAIN PERFORMANCE SUMMARY")
print("=" * 45)
print(f"• {high_critical_count} parts ({high_critical_count/len(df)*100:.1f}%) are high/critical risk")
print(f"• Only {low_risk_count} parts ({low_risk_count/len(df)*100:.1f}%) are truly reliable")
print(f"• Average on-time rate: {avg_on_time:.1f}%")
print(f"• Average lead time: {avg_lead_time:.1f} days")
```

## Parts by Risk Category

```{python}
# Show parts in each risk category
parts_by_risk = {category: df[df['risk_category'] == category]['Product'].tolist() 
                 for category in risk_breakdown.index}

for category, parts in parts_by_risk.items():
    print(f"\n{category} ({len(parts)} parts):")
    print(", ".join(parts[:10]))  # Show first 10 parts
    if len(parts) > 10:
        print(f"... and {len(parts) - 10} more")
```

# Lead Time Analysis

```{python}
# Lead time statistics by risk category
print("Lead Time Statistics by Risk Category:")
print("=" * 50)
for category in ['LOW_RISK', 'MEDIUM_RISK', 'HIGH_RISK', 'CRITICAL_RISK']:
    subset = df[df['risk_category'] == category]
    if len(subset) > 0:
        print(f"\n{category}:")
        print(f"  Average Lead Time: {subset['lead_time_mean'].mean():.1f} days")
        print(f"  Lead Time Std Dev: {subset['lead_time_std'].mean():.1f} days")
        print(f"  Average On-Time Rate: {subset['on_time_rate'].mean():.1f}%")
        print(f"  Parts Count: {len(subset)}")
```

```{python}
# Top 20 Products with Highest Mean Lead Time
top_20_df = df[['Product', 'lead_time_mean']].sort_values('lead_time_mean', ascending=False).head(20)
print("Top 20 Products with Highest Mean Lead Time:")
display(top_20_df)
```

```{python}
# Load problem parts data
problem_parts = pd.read_excel('lead_time_analysis_wf.xlsx', sheet_name='Problem_Parts')

print("🚨 WORST PERFORMING PARTS:")
print("=" * 80)
worst_parts = problem_parts.nsmallest(10, 'on_time_rate')[['Product', 'lead_time_mean', 'on_time_rate', 'risk_category']]
for idx, row in worst_parts.iterrows():
    print(f"Part {row['Product']}: {row['lead_time_mean']:.1f} days avg, {row['on_time_rate']:.1f}% on-time, {row['risk_category']}")

# Visualize the problem
plt.figure(figsize=(14, 8))

plt.subplot(2, 2, 1)
plt.scatter(df['lead_time_mean'], df['on_time_rate'], 
           c=df['lead_time_cv'], cmap='YlOrRd', alpha=0.6)
plt.xlabel('Average Lead Time (days)')
plt.ylabel('On-Time Rate (%)')
plt.title('Lead Time vs Reliability')
plt.colorbar(label='Coefficient of Variation')

plt.subplot(2, 2, 2)
risk_colors = {'LOW_RISK': '#51CF66', 'MEDIUM_RISK': '#FFE66D', 'HIGH_RISK': '#FF9F43', 'CRITICAL_RISK': '#FF6B6B'}
for risk in risk_colors.keys():
    subset = df[df['risk_category'] == risk]
    plt.scatter(subset['lead_time_mean'], subset['lead_time_std'], 
               color=risk_colors[risk], label=risk, alpha=0.7)
plt.xlabel('Mean Lead Time (days)')
plt.ylabel('Lead Time Standard Deviation')
plt.title('Lead Time Variability by Risk Category')
plt.legend()

plt.subplot(2, 2, 3)
plt.boxplot([df[df['risk_category'] == risk]['lead_time_mean'] 
            for risk in ['LOW_RISK', 'MEDIUM_RISK', 'HIGH_RISK', 'CRITICAL_RISK']], 
           labels=['Low', 'Medium', 'High', 'Critical'])
plt.ylabel('Lead Time (days)')
plt.title('Lead Time Distribution by Risk')
plt.xticks(rotation=45)

plt.subplot(2, 2, 4)
cv_by_risk = df.groupby('risk_category')['lead_time_cv'].mean()
bars = plt.bar(cv_by_risk.index, cv_by_risk.values, 
               color=[risk_colors[risk] for risk in cv_by_risk.index])
plt.ylabel('Average Coefficient of Variation')
plt.title('Lead Time Predictability by Risk')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

```


```{python}
overview_df = pd.read_excel('DAN_ATL .xlsx', sheet_name='OVERVIEW')
bundle_df = pd.read_excel('DAN_ATL .xlsx', sheet_name='BUNDLE_QUANTITIES')
weight_df = pd.read_excel('DAN_ATL .xlsx', sheet_name='WEIGHT')
frequency_df = pd.read_excel('DAN_ATL .xlsx', sheet_name='FREQUENCY')

print("🚀 ADVANCED SYSTEM OVERVIEW:")
print("=" * 50)
print(f"Parts in Optimization System: {len(overview_df):,}")
print(f"Total Inventory Value: ${overview_df['INVENTORY_AMOUNT_ONHAND'].sum():,.2f}")
print(f"Projected Annual Demand Value: ${(overview_df['PROJECTED EOY 2025 USAGE'] * overview_df['COST']).sum():,.2f}")

# Key system features
features = [
    "✓ Lead time-adjusted safety stock calculations",
    "✓ Frequency-based categorization system", 
    "✓ Weight-constrained ordering optimization",
    "✓ Cost-aware inventory management",
    "✓ Predictive 2025 demand forecasting",
    "✓ Multi-tier urgency level system",
    "✓ Bundle quantity optimization"
]

print("\nSystem Features:")
for feature in features:
    print(feature)
```

```{python}
plt.figure(figsize=(16, 10))

# Current vs Optimal Safety Stock
plt.subplot(2, 3, 1)
plt.scatter(overview_df['SAFETY_STOCK'], overview_df['OPTIMAL_SAFETY_STOCK'], alpha=0.6)
plt.plot([0, overview_df['SAFETY_STOCK'].max()], [0, overview_df['SAFETY_STOCK'].max()], 'r--', label='1:1 Line')
plt.xlabel('Current Safety Stock')
plt.ylabel('Optimal Safety Stock')
plt.title('Safety Stock Optimization')
plt.legend()

# Potential Savings Distribution
plt.subplot(2, 3, 2)
savings_data = overview_df['POTENTIAL_SAVINGS'].dropna()
plt.hist(savings_data, bins=30, alpha=0.7, color='green', edgecolor='black')
plt.xlabel('Potential Savings ($)')
plt.ylabel('Number of Parts')
plt.title(f'Potential Savings Distribution\nTotal: ${savings_data.sum():,.2f}')

# Days on Hand Analysis
plt.subplot(2, 3, 3)
plt.hist(overview_df['DAYS_ON_HAND'], bins=30, alpha=0.7, color='blue', edgecolor='black')
plt.xlabel('Days on Hand')
plt.ylabel('Number of Parts')
plt.title('Current Inventory Coverage')
plt.axvline(overview_df['DAYS_ON_HAND'].median(), color='red', linestyle='--', 
            label=f'Median: {overview_df["DAYS_ON_HAND"].median():.0f} days')
plt.legend()

# Frequency Category Analysis
plt.subplot(2, 3, 4)
freq_analysis = overview_df['FREQUENCY_CATEGORY'].value_counts()
colors = plt.cm.Set3(np.linspace(0, 1, len(freq_analysis)))
plt.pie(freq_analysis.values, labels=freq_analysis.index, autopct='%1.1f%%', colors=colors)
plt.title('Parts by Frequency Category')

# Lead Time vs Current Usage
plt.subplot(2, 3, 5)
plt.scatter(overview_df['LEAD_TIME'], overview_df['CURRENT_MONTHLY_USAGE'], 
           c=overview_df['FREQUENCY'], cmap='viridis', alpha=0.6)
plt.xlabel('Lead Time (days)')
plt.ylabel('Current Monthly Usage')
plt.title('Usage Patterns vs Lead Time')
plt.colorbar(label='Frequency Score')

# Urgency Level Distribution
plt.subplot(2, 3, 6)
urgency_counts = overview_df['URGENCY_LEVEL'].value_counts()
colors = ['#FF6B6B', '#FFE66D', '#51CF66']  # Red, Yellow, Green
plt.bar(urgency_counts.index, urgency_counts.values, color=colors[:len(urgency_counts)])
plt.xlabel('Urgency Level')
plt.ylabel('Number of Parts')
plt.title('Action Priority Distribution')

plt.tight_layout()
plt.show()

# Key insights
print("\n📊 OPTIMIZATION INSIGHTS:")
print("=" * 50)
total_current_safety = overview_df['SAFETY_STOCK'].sum()
total_optimal_safety = overview_df['OPTIMAL_SAFETY_STOCK'].sum()
total_savings = overview_df['POTENTIAL_SAVINGS'].sum()

print(f"Current Total Safety Stock: {total_current_safety:,.0f} units")
print(f"Optimal Total Safety Stock: {total_optimal_safety:,.0f} units")
print(f"Total Potential Savings: ${total_savings:,.2f}")
print(f"Average Days Coverage: {overview_df['DAYS_ON_HAND'].mean():.1f} days")
print(f"Parts Requiring Immediate Attention: {(overview_df['URGENCY_LEVEL'] == 'HIGH').sum()}")
```

```{python}
safety_factor_analysis = pd.merge(overview_df[['PART_NUMBER', 'SAFETY_FACTOR', 'FREQUENCY_CATEGORY', 'LEAD_TIME']], 
                                 df[['Product', 'risk_category', 'lead_time_cv']], 
                                 left_on='PART_NUMBER', right_on='Product', how='inner')

print("Safety Factor by Risk Category:")
risk_safety = safety_factor_analysis.groupby('risk_category')['SAFETY_FACTOR'].agg(['mean', 'std', 'count'])
print(risk_safety)

# Visualize the relationship
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
risk_categories = ['LOW_RISK', 'MEDIUM_RISK', 'HIGH_RISK', 'CRITICAL_RISK']
safety_by_risk = [safety_factor_analysis[safety_factor_analysis['risk_category'] == risk]['SAFETY_FACTOR'].values 
                 for risk in risk_categories]
bp = plt.boxplot(safety_by_risk, labels=risk_categories, patch_artist=True)
colors = ['#51CF66', '#FFE66D', '#FF9F43', '#FF6B6B']
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)
plt.ylabel('Safety Factor')
plt.title('Safety Factor Distribution by Risk Category')
plt.xticks(rotation=45)

plt.subplot(1, 2, 2)
# Map FREQUENCY_CATEGORY to numeric codes for coloring
freq_map = {cat: idx for idx, cat in enumerate(safety_factor_analysis['FREQUENCY_CATEGORY'].unique())}
freq_numeric = safety_factor_analysis['FREQUENCY_CATEGORY'].map(freq_map)
scatter = plt.scatter(safety_factor_analysis['lead_time_cv'], safety_factor_analysis['SAFETY_FACTOR'], 
                      c=freq_numeric, cmap='viridis', alpha=0.7)
plt.xlabel('Lead Time Coefficient of Variation')
plt.ylabel('Safety Factor')
plt.title('Safety Factor vs Lead Time Variability')
cbar = plt.colorbar(scatter, ticks=list(freq_map.values()))
cbar.ax.set_yticklabels(list(freq_map.keys()))
cbar.set_label('Frequency Category')

plt.tight_layout()
plt.show()
```



# Conclusions and Recommendations

## Critical Issues Identified

1. **Supply Chain Reliability Crisis**: With 77.9% of parts in high/critical risk categories, immediate action is required
2. **Poor On-Time Performance**: 40.1% average on-time rate is well below industry standards
3. **Limited Reliable Suppliers**: Only 7 parts (3.6%) demonstrate consistent reliability

## Recommended Actions

### Immediate (0-3 months)
- Focus on the 34 **CRITICAL_RISK** parts for supplier diversification
- Implement enhanced monitoring for high-risk categories
- Negotiate service level agreements with key suppliers

### Medium-term (3-12 months)
- Develop alternative suppliers for high-risk parts
- Implement predictive analytics for lead time forecasting
- Create safety stock strategies based on risk categories

### Long-term (12+ months)
- Strategic supplier partnerships with reliable vendors
- Supply chain digitization and real-time tracking
- Continuous improvement programs targeting lead time reduction

## Success Metrics
- Target: Reduce high/critical risk parts from 77.9% to <50%
- Target: Improve average on-time rate from 40.1% to >80%
- Target: Increase reliable parts from 3.6% to >25%